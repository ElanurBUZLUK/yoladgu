# ğŸš€ Adaptive Question Recommendation System - Backend

**AI-Powered Personalized Question Recommendation System for Math and English**

Bu proje, Ã¶ÄŸrencilerin matematik ve Ä°ngilizce alanlarÄ±nda kiÅŸiselleÅŸtirilmiÅŸ soru Ã¶nerileri alan adaptif bir Ã¶ÄŸrenme sistemidir. Sistem, Ã¶ÄŸrencinin geÃ§miÅŸ performansÄ±nÄ± analiz ederek IRT (Item Response Theory), bandit algoritmalarÄ± ve **Vector Database** teknolojileri kullanarak en uygun sorularÄ± Ã¶nerir ve gerektiÄŸinde yeni sorular Ã¼retir.

## âœ¨ **Yeni Ã–zellikler (v2.0)**

### ğŸ¯ **Multi-Backend Vector Indexing**
- **Qdrant**: Production-ready vector database
- **HNSW**: High-performance approximate nearest neighbor search
- **FAISS**: Facebook AI Similarity Search for exact search
- **ML-based Backend Selection**: Intelligent backend routing

### ğŸ§  **Enhanced AI Generation**
- **English E2E Pipeline**: Complete cloze generation workflow
- **Vector Examples Enhancement**: Real examples for better distractors
- **Error-Aware Recommendations**: Student error profile analysis
- **Hybrid Retrieval**: Dense + Sparse search combination

### ğŸ“Š **Advanced Monitoring**
- **Comprehensive Dashboard**: Vector + Search + Performance metrics
- **Health Checks**: Multi-backend status monitoring
- **Performance Analytics**: Latency, accuracy, and quality metrics

## ğŸ—ï¸ **Mimari (GÃ¼ncellenmiÅŸ)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Ä°stemci       â”‚â”€â”€â”€â–¶â”‚   API Gateway   â”‚â”€â”€â”€â–¶â”‚  Orchestrator   â”‚
â”‚   UygulamasÄ±    â”‚    â”‚   (FastAPI)     â”‚    â”‚    Service      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚                                â”‚                                â”‚
                       â–¼                                â–¼                                â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Profile Service â”‚              â”‚Retrieval Serviceâ”‚              â”‚ Bandit Service  â”‚
              â”‚   (IRT/BKT)     â”‚              â”‚ (Hybrid Search) â”‚              â”‚  (LinUCB/TS)    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚                                â”‚                                â”‚
                       â–¼                                â–¼                                â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   PostgreSQL    â”‚              â”‚ Vector Manager  â”‚              â”‚ Generation      â”‚
              â”‚ (User Profiles) â”‚              â”‚ (Qdrant/HNSW/   â”‚              â”‚ Service (LLM)   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚  FAISS)         â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚                                â”‚                                â”‚
                       â–¼                                â–¼                                â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Redis Cache   â”‚              â”‚ Elasticsearch   â”‚              â”‚ Vector Examples â”‚
              â”‚   (Profiles)    â”‚              â”‚  (Sparse Search) â”‚              â”‚   Service       â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ **Teknoloji Stack (GÃ¼ncellenmiÅŸ)**

### **Core Framework**
- **Backend**: FastAPI + SQLModel
- **Database**: PostgreSQL + Redis
- **ORM**: SQLAlchemy + Alembic

### **Vector & Search**
- **Vector Databases**: Qdrant, HNSW, FAISS
- **Search Engine**: Elasticsearch
- **Embeddings**: Sentence Transformers (multilingual)
- **Vector Manager**: Custom multi-backend orchestration

### **AI/ML Services**
- **Language Models**: Sentence Transformers
- **Math Processing**: SymPy, NumPy
- **ML Backend Selector**: RandomForest classifier
- **Recommendation**: Error-aware + neighbor-lift scoring

### **Infrastructure**
- **Containerization**: Docker + Docker Compose
- **Monitoring**: Custom metrics + health checks
- **Testing**: Pytest + coverage
- **CI/CD**: GitHub Actions ready

## ğŸ“‹ **Gereksinimler**

### **System Requirements**
- Python 3.11+
- Docker & Docker Compose
- PostgreSQL 15+
- Redis 7+
- Elasticsearch 8+

### **Python Dependencies**
```bash
# Core ML/AI
sentence-transformers>=2.2.2
scikit-learn>=1.7.1
numpy>=1.24.0
scipy>=1.11.0

# Vector Databases
qdrant-client>=1.7.0
hnswlib>=0.8.0
faiss-cpu>=1.7.4

# Search & Cache
elasticsearch>=9.1.0
redis>=6.4.0

# Web Framework
fastapi>=0.104.0
uvicorn>=0.24.0
sqlmodel>=0.0.24
```

## ğŸš€ **Kurulum**

### **1. Repository'yi klonlayÄ±n**
```bash
git clone https://github.com/ElanurBUZLUK/yoladgu.git
cd yoladgu/backend
```

### **2. Environment dosyasÄ±nÄ± oluÅŸturun**
```bash
cp .env.example .env
# .env dosyasÄ±nÄ± dÃ¼zenleyerek gerekli konfigÃ¼rasyonlarÄ± yapÄ±n
```

### **3. Virtual Environment oluÅŸturun**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# veya
venv\Scripts\activate     # Windows
```

### **4. Dependencies yÃ¼kleyin**
```bash
pip install -r requirements.txt
```

### **5. Docker Compose ile servisleri baÅŸlatÄ±n**
```bash
docker-compose up -d
```

### **6. VeritabanÄ± migration'larÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±n**
```bash
alembic upgrade head
```

### **7. ML Backend Selector'Ä± eÄŸitin**
```bash
python train_backend_selector.py
```

### **8. UygulamayÄ± baÅŸlatÄ±n**
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### **9. API dokÃ¼mantasyonuna eriÅŸin**
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **Health Check**: http://localhost:8000/health

## ğŸ”§ **Vector Database YapÄ±landÄ±rmasÄ±**

### **1. FAISS Index OluÅŸturma**
```python
from app.services.index_backends.faiss_flat_index import FAISSFlatIndexBackend

# FAISS backend'i baÅŸlat
faiss_backend = FAISSFlatIndexBackend(
    vector_size=384,  # sentence-transformers boyutu
    metric="ip"       # Inner Product (cosine similarity)
)

# Initialize
await faiss_backend.initialize()
```

### **2. HNSW Index YapÄ±landÄ±rmasÄ±**
```python
from app.services.index_backends.hnsw_index import HNSWIndexBackend

# HNSW backend'i baÅŸlat
hnsw_backend = HNSWIndexBackend(
    vector_size=384,
    max_elements=10000,
    ef_construction=200,
    m=16
)

# Initialize
await hnsw_backend.initialize()
```

### **3. Qdrant BaÄŸlantÄ±sÄ±**
```python
from app.services.index_backends.qdrant_index import QdrantIndexBackend

# Qdrant backend'i baÅŸlat
qdrant_backend = QdrantIndexBackend(
    collection_name="english_items",
    vector_size=384,
    url="http://localhost:6333"
)

# Initialize
await qdrant_backend.initialize()
```

### **4. Embedding Model YapÄ±landÄ±rmasÄ±**
```python
from sentence_transformers import SentenceTransformer

# Multilingual model (384 dimensions)
encoder = SentenceTransformer(
    "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
)

# Enhanced embedding with metadata
enhanced_text = f"{text} [ERROR_TAGS]: {', '.join(error_tags)} [LEVEL]: {cefr_level}"
vector = encoder.encode(enhanced_text)
```

## ğŸ“ **Proje YapÄ±sÄ± (GÃ¼ncellenmiÅŸ)**

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/                    # API endpoints
â”‚   â”‚   â””â”€â”€ v1/                # API v1 routes
â”‚   â”‚       â”œâ”€â”€ generate.py    # Question generation
â”‚   â”‚       â”œâ”€â”€ vector.py      # Vector operations
â”‚   â”‚       â”œâ”€â”€ recommendations.py # Error-aware recommendations
â”‚   â”‚       â””â”€â”€ admin.py       # Admin operations
â”‚   â”œâ”€â”€ core/                  # Core configuration
â”‚   â”œâ”€â”€ db/                    # Database models & repositories
â”‚   â”œâ”€â”€ models/                # Pydantic models
â”‚   â”œâ”€â”€ services/              # Business logic services
â”‚   â”‚   â”œâ”€â”€ index_backends/    # Vector database backends
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py        # Abstract base class
â”‚   â”‚   â”‚   â”œâ”€â”€ qdrant_index.py
â”‚   â”‚   â”‚   â”œâ”€â”€ hnsw_index.py
â”‚   â”‚   â”‚   â””â”€â”€ faiss_flat_index.py
â”‚   â”‚   â”œâ”€â”€ ml/                # ML services
â”‚   â”‚   â”‚   â”œâ”€â”€ backend_selector.py
â”‚   â”‚   â”‚   â””â”€â”€ feature_extractor.py
â”‚   â”‚   â”œâ”€â”€ recommenders/      # Recommendation engines
â”‚   â”‚   â”‚   â””â”€â”€ error_aware.py
â”‚   â”‚   â””â”€â”€ vector_service.py  # Vector operations
â”‚   â””â”€â”€ main.py                # FastAPI application
â”œâ”€â”€ tests/                     # Test files
â”œâ”€â”€ data/                      # Data files
â”‚   â””â”€â”€ ml/                    # ML models
â”‚       â””â”€â”€ backend_selector.joblib
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ Dockerfile                 # Docker configuration
â”œâ”€â”€ docker-compose.yml         # Docker Compose setup
â”œâ”€â”€ train_backend_selector.py  # ML model training
â””â”€â”€ README.md                  # This file
```

## ğŸ“Š **API Endpoints (GÃ¼ncellenmiÅŸ)**

### **ğŸ” Authentication**
- `POST /api/v1/auth/login` - KullanÄ±cÄ± giriÅŸi
- `POST /api/v1/auth/register` - KullanÄ±cÄ± kaydÄ±

### **ğŸ¯ Question Generation**
- `POST /api/v1/generate/en_cloze` - Ä°ngilizce cloze sorusu Ã¼retimi
- `POST /api/v1/generate/math` - Matematik sorusu Ã¼retimi
- `GET /api/v1/templates/english` - Ä°ngilizce ÅŸablonlarÄ±

### **ğŸ” Vector Operations**
- `GET /api/v1/vector/health` - Vector backends health
- `GET /api/v1/vector/stats` - Vector service statistics
- `GET /api/v1/vector/monitoring` - Comprehensive monitoring
- `POST /api/v1/vector/search` - Vector search
- `POST /api/v1/vector/add` - Add vector item
- `POST /api/v1/vector/add-batch` - Batch add items

### **ğŸ“š Recommendations**
- `POST /api/v1/recommendations/error-aware` - Error-aware recommendations
- `POST /api/v1/recommendations/error-aware/batch` - Batch recommendations
- `GET /api/v1/recommendations/error-aware/stats` - Service statistics

### **âš™ï¸ Administration**
- `POST /api/v1/admin/reindex_english` - Reindex English items
- `POST /api/v1/admin/reindex_math` - Reindex Math items

## ğŸ§ª **Testing & Development**

### **Local Development**
```bash
# Virtual environment
source venv/bin/activate

# Run tests
pytest

# Run specific test
pytest tests/test_vector_service.py -v

# Coverage report
pytest --cov=app tests/ --cov-report=html
```

### **Vector Service Testing**
```bash
# Test vector operations
python test_vector_index_manager.py

# Test ML backend selector
python train_backend_selector.py

# Test English generation
python test_english_cloze_generation.py
```

### **Code Quality**
```bash
# Code formatting
black app/
isort app/

# Linting
flake8 app/
mypy app/
```

## ğŸ” **Monitoring & Health Checks**

### **Health Endpoints**
```bash
# System health
GET /health

# Vector backends health
GET /api/v1/vector/health

# Comprehensive monitoring
GET /api/v1/vector/monitoring
```

### **Performance Metrics**
- **Latency**: p50, p95, p99
- **Throughput**: requests/second
- **Error Rate**: percentage
- **Vector Search**: accuracy, recall
- **Backend Usage**: per-backend statistics

## ğŸš¨ **Troubleshooting**

### **Vector Database Issues**

#### **FAISS Connection Error**
```bash
# Check FAISS installation
python -c "import faiss; print('FAISS OK')"

# Reinstall if needed
pip uninstall faiss-cpu
pip install faiss-cpu
```

#### **HNSW Index Error**
```bash
# Check HNSW installation
python -c "import hnswlib; print('HNSW OK')"

# Reinstall if needed
pip uninstall hnswlib
pip install hnswlib
```

#### **Qdrant Connection Error**
```bash
# Check Qdrant service
docker-compose ps qdrant

# Restart if needed
docker-compose restart qdrant
```

### **Embedding Issues**

#### **Model Download Error**
```bash
# Clear cache
rm -rf ~/.cache/torch/sentence_transformers/

# Reinstall sentence-transformers
pip uninstall sentence-transformers
pip install sentence-transformers
```

#### **Memory Issues**
```bash
# Reduce batch size in vector_service.py
BATCH_SIZE = 100  # Default: 1000

# Use smaller embedding model
model_name = "sentence-transformers/all-MiniLM-L6-v2"  # 384d instead of 768d
```

### **Database Issues**

#### **Migration Errors**
```bash
# Reset migrations
alembic downgrade base
alembic upgrade head

# Check database connection
python -c "from app.db.base import async_engine; print('DB OK')"
```

## ğŸ“ˆ **Performance Optimization**

### **Vector Search Optimization**
```python
# Use appropriate backend for query type
if k > 100:
    backend = "faiss"  # Exact search for large k
elif filters:
    backend = "qdrant"  # Filtered search
else:
    backend = "hnsw"    # Fast approximate search

# Enable hybrid search for better results
results = await vector_service.search(
    query=query,
    limit=k,
    use_hybrid=True,
    use_mmr=True,
    mmr_lambda=0.7
)
```

### **Caching Strategy**
```python
# Redis caching for frequently accessed data
CACHE_TTL = {
    "user_profile": 3600,      # 1 hour
    "vector_results": 86400,    # 24 hours
    "recommendations": 1800,    # 30 minutes
}
```

## ğŸ¤ **KatkÄ±da Bulunma**

### **Development Workflow**
1. **Fork** yapÄ±n
2. **Feature branch** oluÅŸturun (`git checkout -b feature/amazing-feature`)
3. **Commit** yapÄ±n (`git commit -m 'Add amazing feature'`)
4. **Push** yapÄ±n (`git push origin feature/amazing-feature`)
5. **Pull Request** aÃ§Ä±n

### **Code Standards**
- **Python**: PEP 8, type hints
- **API**: OpenAPI 3.0 specification
- **Testing**: 90%+ coverage required
- **Documentation**: Docstrings for all functions

## ğŸ“„ **Lisans**

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in [LICENSE](LICENSE) dosyasÄ±na bakÄ±n.

## ğŸ“ **Ä°letiÅŸim & Support**

### **GitHub Issues**
- **Bug Reports**: [New Issue](https://github.com/ElanurBUZLUK/yoladgu/issues/new)
- **Feature Requests**: [New Issue](https://github.com/ElanurBUZLUK/yoladgu/issues/new)
- **Documentation**: [Wiki](https://github.com/ElanurBUZLUK/yoladgu/wiki)

### **Maintainers**
- **Elanur Buzluk** - [@ElanurBUZLUK](https://github.com/ElanurBUZLUK)

---

## ğŸ¯ **Quick Start Checklist**

- [ ] Repository cloned
- [ ] Environment configured (.env)
- [ ] Dependencies installed
- [ ] Docker services running
- [ ] Database migrated
- [ ] ML model trained
- [ ] Application started
- [ ] Health checks passed
- [ ] API documentation accessible

**ğŸš€ Ready to build amazing AI-powered learning experiences!**